#!/usr/bin/env python3
"""
ML Model - –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –ø—Ä–æ–¥—É–∫—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Ollama
by Morzh - –ü—Ä–æ–µ–∫—Ç —Å–æ–∑–¥–∞–Ω –¥–ª—è —Ä–∞–∑–≤–∏—Ç–∏—è –≤–∞–ª–∏–¥–∞—Ç–æ—Ä–∞ —Ç–æ–≤–∞—Ä–æ–≤ —ç–ª–µ–∫—Ç—Ä–æ–Ω–∏–∫–∏
"""

import json
import logging
import time
import subprocess
import sys
import psutil
import threading
from typing import Dict, Any

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –¥–ª—è Windows
if sys.platform == "win32":
    import os
    os.environ['PYTHONIOENCODING'] = 'utf-8'

logger = logging.getLogger(__name__)

class ResourceMonitor:
    """–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Ä–µ—Å—É—Ä—Å–æ–≤ —Å–∏—Å—Ç–µ–º—ã"""
    
    def __init__(self):
        self.monitoring = False
        self.stats = {}
    
    def start_monitoring(self):
        """–ù–∞—á–∞—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Ä–µ—Å—É—Ä—Å–æ–≤"""
        self.monitoring = True
        self.monitor_thread = threading.Thread(target=self._monitor_loop)
        self.monitor_thread.daemon = True
        self.monitor_thread.start()
    
    def stop_monitoring(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥"""
        self.monitoring = False
    
    def _monitor_loop(self):
        """–¶–∏–∫–ª –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"""
        while self.monitoring:
            try:
                cpu_percent = psutil.cpu_percent(interval=1)
                memory = psutil.virtual_memory()
                gpu_info = self._get_gpu_info()
                
                self.stats = {
                    'cpu_percent': cpu_percent,
                    'ram_percent': memory.percent,
                    'ram_used_gb': memory.used / (1024**3),
                    'ram_total_gb': memory.total / (1024**3),
                    'gpu_info': gpu_info,
                    'timestamp': time.time()
                }
                
                time.sleep(1)
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞: {e}")
                time.sleep(2)
    
    def _get_gpu_info(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ GPU"""
        try:
            result = subprocess.run(
                ['nvidia-smi', '--query-gpu=name,memory.used,memory.total,utilization.gpu', 
                 '--format=csv,noheader,nounits'],
                capture_output=True,
                text=True,
                timeout=5
            )
            
            if result.returncode == 0:
                lines = result.stdout.strip().split('\n')
                gpu_info = []
                
                for line in lines:
                    if line.strip():
                        parts = line.split(', ')
                        if len(parts) >= 4:
                            gpu_info.append({
                                'name': parts[0],
                                'memory_used_mb': int(parts[1]),
                                'memory_total_mb': int(parts[2]),
                                'utilization_percent': int(parts[3])
                            })
                
                return gpu_info
            else:
                return []
                
        except (subprocess.TimeoutExpired, FileNotFoundError, Exception):
            return []
    
    def get_current_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        return self.stats.copy()

class ProductClassifier:
    """–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –ø—Ä–æ–¥—É–∫—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–æ–¥–µ–ª–∏ T-pro-it-2.0"""
    
    def __init__(self):
        self.model_name = "t-pro-it-2.0-optimized"
        self.is_loaded = False
        self.categories = [
            "iphone", "processors", "videocards", "motherboards", 
            "playstation", "nintendo-switch", "steam-deck"
        ]
        self.resource_monitor = ResourceMonitor()
    
    def get_model_info(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏"""
        return {
            "model_name": self.model_name,
            "is_loaded": self.is_loaded,
            "method": "t_pro_it_2_0",
            "categories": self.categories,
            "platform": sys.platform,
            "model_size_gb": 12.3
        }
    
    def load_model(self) -> bool:
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å T-pro-it-2.0"""
        try:
            logger.info(f"–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å {self.model_name} (T-pro-it-2.0)...")
            
            self.resource_monitor.start_monitoring()
            
            result = subprocess.run(
                ["ollama", "list"], 
                capture_output=True, 
                text=True, 
                encoding='utf-8'
            )
            
            if result.returncode != 0:
                logger.error("–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                return False
            
            if self.model_name not in result.stdout:
                logger.error(f"–ú–æ–¥–µ–ª—å {self.model_name} (T-pro-it-2.0) –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                return False
            
            self.is_loaded = True
            logger.info("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
            
            stats = self.resource_monitor.get_current_stats()
            logger.info(f"üìä –†–µ—Å—É—Ä—Å—ã: CPU {stats.get('cpu_percent', 0):.1f}%, RAM {stats.get('ram_percent', 0):.1f}%")
            
            return True
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {str(e)}")
            return False
    
    def classify_products_batch(self, products: list) -> list:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–æ–¥—É–∫—Ç–æ–≤ –æ–¥–Ω–∏–º –∑–∞–ø—Ä–æ—Å–æ–º"""
        if not self.is_loaded:
            return [{"error": "–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞"}] * len(products)
        
        try:
            prompt = self._create_batch_prompt(products)
            
            logger.info(f"üîç –ë–∞—Ç—á –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è: {len(products)} —Ç–æ–≤–∞—Ä–æ–≤")
            
            # ASCII-–∞—Ä—Ç –∞–Ω–∏–º–∞—Ü–∏—è –¥–ª—è –±–∞—Ç—á–∞
            loading_frames = ["8uu==3", "8==uu3"]
            current_frame = 0
            animation_running = True
            
            def animate():
                nonlocal current_frame
                while animation_running:
                    frame = loading_frames[current_frame % len(loading_frames)]
                    sys.stdout.write(f"\r‚è≥ {frame} –ë–∞—Ç—á –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è {len(products)} —Ç–æ–≤–∞—Ä–æ–≤...")
                    sys.stdout.flush()
                    current_frame += 1
                    time.sleep(0.3)
            
            animation_thread = threading.Thread(target=animate, daemon=True)
            animation_thread.start()
            
            start_time = time.time()
            result = subprocess.run(
                ["ollama", "run", self.model_name, prompt],
                capture_output=True,
                text=True,
                encoding='utf-8',
                timeout=300  # –ë–æ–ª—å—à–µ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –±–∞—Ç—á–∞
            )
            
            animation_running = False
            sys.stdout.write("\r" + " " * 80 + "\r")
            sys.stdout.flush()
            
            elapsed_time = time.time() - start_time
            
            if result.returncode != 0:
                return [{"error": f"–û—à–∏–±–∫–∞ –º–æ–¥–µ–ª–∏: {result.stderr}"}] * len(products)
            
            response = result.stdout.strip()
            stats = self.resource_monitor.get_current_stats()
            
            logger.info(f"‚úÖ –ë–∞—Ç—á –≥–æ—Ç–æ–≤! –í—Ä–µ–º—è: {elapsed_time:.2f} —Å–µ–∫ ({elapsed_time/len(products):.2f} —Å–µ–∫/—Ç–æ–≤–∞—Ä)")
            logger.debug(f"–û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏: {response[:500]}...")
            
            return self._parse_batch_response(response, products, elapsed_time, stats)
            
        except subprocess.TimeoutExpired:
            animation_running = False
            sys.stdout.write("\r" + " " * 80 + "\r")
            sys.stdout.flush()
            return [{"error": "–¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –±–∞—Ç—á –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"}] * len(products)
        except Exception as e:
            animation_running = False
            sys.stdout.write("\r" + " " * 80 + "\r")
            sys.stdout.flush()
            return [{"error": f"–û—à–∏–±–∫–∞ –±–∞—Ç—á –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {str(e)}"}] * len(products)

    def classify_product(self, product: Dict[str, str]) -> Dict[str, Any]:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–¥—É–∫—Ç"""
        if not self.is_loaded:
            return {"error": "–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞"}
        
        try:
            prompt = self._create_classification_prompt(product)
            
            stats = self.resource_monitor.get_current_stats()
            logger.info(f"üîç –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è: {product.get('name', '')[:30]}...")
            
            # ASCII-–∞—Ä—Ç –∞–Ω–∏–º–∞—Ü–∏—è
            loading_frames = ["8uu==3", "8==uu3"]
            current_frame = 0
            animation_running = True
            
            def animate():
                nonlocal current_frame
                while animation_running:
                    frame = loading_frames[current_frame % len(loading_frames)]
                    sys.stdout.write(f"\r‚è≥ {frame} {product.get('name', '')[:30]}...")
                    sys.stdout.flush()
                    current_frame += 1
                    time.sleep(0.3)
            
            animation_thread = threading.Thread(target=animate, daemon=True)
            animation_thread.start()
            
            start_time = time.time()
            result = subprocess.run(
                ["ollama", "run", self.model_name, prompt],
                capture_output=True,
                text=True,
                encoding='utf-8',
                timeout=120
            )
            
            animation_running = False
            sys.stdout.write("\r" + " " * 80 + "\r")
            sys.stdout.flush()
            
            elapsed_time = time.time() - start_time
            
            if result.returncode != 0:
                return {"error": f"–û—à–∏–±–∫–∞ Ollama: {result.stderr}"}
            
            response = result.stdout.strip()
            
            stats = self.resource_monitor.get_current_stats()
            logger.info(f"‚úÖ –ì–æ—Ç–æ–≤–æ! –í—Ä–µ–º—è: {elapsed_time:.2f} —Å–µ–∫")
            
            parsed_response = self._parse_classification_response(response)
            
            return {
                "product_name": product.get("name", ""),
                "predicted_category": parsed_response.get("category", "unknown"),
                "confidence": parsed_response.get("confidence", 0.0),
                "full_response": response,
                "method": "ollama",
                "processing_time": elapsed_time,
                "resources": stats
            }
            
        except subprocess.TimeoutExpired:
            animation_running = False
            sys.stdout.write("\r" + " " * 80 + "\r")
            sys.stdout.flush()
            return {"error": "–¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"}
        except Exception as e:
            animation_running = False
            sys.stdout.write("\r" + " " * 80 + "\r")
            sys.stdout.flush()
            return {"error": f"–û—à–∏–±–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {str(e)}"}
    
    def _create_batch_prompt(self, products: list) -> str:
        """–°–æ–∑–¥–∞—Ç—å –ø—Ä–æ–º–ø—Ç –¥–ª—è –±–∞—Ç—á –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        categories_str = ", ".join(self.categories)
        
        products_text = ""
        for i, product in enumerate(products, 1):
            products_text += f"""
{i}. –¢–æ–≤–∞—Ä: {product.get('name', '')}
   –û–ø–∏—Å–∞–Ω–∏–µ: {product.get('description', '')}
"""
        
        prompt = f"""
–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–π –≤—Å–µ —Ç–æ–≤–∞—Ä—ã –ø–æ –æ–¥–Ω–æ–π –∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {categories_str}

{products_text}

–û—Ç–≤–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON –º–∞—Å—Å–∏–≤:
[
  {{
    "index": 1,
    "category": "–Ω–∞–∑–≤–∞–Ω–∏–µ_–∫–∞—Ç–µ–≥–æ—Ä–∏–∏",
    "confidence": 0.95,
    "reasoning": "–æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –≤—ã–±–æ—Ä–∞"
  }},
  {{
    "index": 2,
    "category": "–Ω–∞–∑–≤–∞–Ω–∏–µ_–∫–∞—Ç–µ–≥–æ—Ä–∏–∏", 
    "confidence": 0.95,
    "reasoning": "–æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –≤—ã–±–æ—Ä–∞"
  }}
]

–ï—Å–ª–∏ –Ω–µ –º–æ–∂–µ—à—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏—é, –∏—Å–ø–æ–ª—å–∑—É–π "unknown" —Å confidence 0.0.
"""
        return prompt.strip()

    def _create_classification_prompt(self, product: Dict[str, str]) -> str:
        """–°–æ–∑–¥–∞—Ç—å –ø—Ä–æ–º–ø—Ç –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        categories_str = ", ".join(self.categories)
        
        prompt = f"""
–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–π —Ç–æ–≤–∞—Ä –ø–æ –æ–¥–Ω–æ–π –∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {categories_str}

–¢–æ–≤–∞—Ä: {product.get('name', '')}
–û–ø–∏—Å–∞–Ω–∏–µ: {product.get('description', '')}

–û—Ç–≤–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON:
{{
  "category": "–Ω–∞–∑–≤–∞–Ω–∏–µ_–∫–∞—Ç–µ–≥–æ—Ä–∏–∏",
  "confidence": 0.95,
  "reasoning": "–æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –≤—ã–±–æ—Ä–∞"
}}

–ï—Å–ª–∏ –Ω–µ –º–æ–∂–µ—à—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏—é, –∏—Å–ø–æ–ª—å–∑—É–π "unknown" —Å confidence 0.0.
"""
        return prompt.strip()
    
    def _parse_batch_response(self, response: str, products: list, elapsed_time: float, stats: dict) -> list:
        """–ü–∞—Ä—Å–∏—Ç—å –±–∞—Ç—á –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏"""
        try:
            start = response.find('[')
            end = response.rfind(']') + 1
            
            if start != -1 and end != 0:
                json_str = response[start:end]
                parsed_results = json.loads(json_str)
                
                results = []
                for i, product in enumerate(products):
                    # –ò—â–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ –∏–Ω–¥–µ–∫—Å—É
                    product_result = None
                    for result in parsed_results:
                        if result.get('index') == i + 1:
                            product_result = result
                            break
                    
                    if product_result:
                        results.append({
                            "product_name": product.get("name", ""),
                            "predicted_category": product_result.get("category", "unknown"),
                            "confidence": product_result.get("confidence", 0.0),
                            "full_response": response,
                            "method": "ollama_batch",
                            "processing_time": elapsed_time / len(products),
                            "resources": stats
                        })
                    else:
                        results.append({
                            "product_name": product.get("name", ""),
                            "predicted_category": "unknown",
                            "confidence": 0.0,
                            "full_response": response,
                            "method": "ollama_batch",
                            "processing_time": elapsed_time / len(products),
                            "resources": stats
                        })
                
                return results
            else:
                # Fallback - —Å–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                results = []
                for product in products:
                    # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—é –≤ —Ç–µ–∫—Å—Ç–µ
                    category = "unknown"
                    confidence = 0.0
                    
                    for cat in self.categories:
                        if cat.lower() in response.lower():
                            category = cat
                            confidence = 0.6
                            break
                    
                    results.append({
                        "product_name": product.get("name", ""),
                        "predicted_category": category,
                        "confidence": confidence,
                        "full_response": response,
                        "method": "ollama_batch_fallback",
                        "processing_time": elapsed_time / len(products),
                        "resources": stats
                    })
                
                return results
                
        except json.JSONDecodeError:
            # Fallback - —Å–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            results = []
            for product in products:
                # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—é –≤ —Ç–µ–∫—Å—Ç–µ
                category = "unknown"
                confidence = 0.0
                
                for cat in self.categories:
                    if cat.lower() in response.lower():
                        category = cat
                        confidence = 0.6
                        break
                
                results.append({
                    "product_name": product.get("name", ""),
                    "predicted_category": category,
                    "confidence": confidence,
                    "full_response": response,
                    "method": "ollama_batch_fallback",
                    "processing_time": elapsed_time / len(products),
                    "resources": stats
                })
            
            return results

    def _parse_classification_response(self, response: str) -> Dict[str, Any]:
        """–ü–∞—Ä—Å–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏"""
        try:
            start = response.find('{')
            end = response.rfind('}') + 1
            
            if start != -1 and end != 0:
                json_str = response[start:end]
                parsed = json.loads(json_str)
                return parsed
            else:
                for category in self.categories:
                    if category.lower() in response.lower():
                        return {
                            "category": category,
                            "confidence": 0.7,
                            "reasoning": "–ò–∑–≤–ª–µ—á–µ–Ω–æ –∏–∑ —Ç–µ–∫—Å—Ç–∞"
                        }
                
                return {"category": "unknown", "confidence": 0.0}
                
        except json.JSONDecodeError:
            for category in self.categories:
                if category.lower() in response.lower():
                    return {
                        "category": category,
                        "confidence": 0.6,
                        "reasoning": "–ò–∑–≤–ª–µ—á–µ–Ω–æ –∏–∑ —Ç–µ–∫—Å—Ç–∞"
                    }
            
            return {"category": "unknown", "confidence": 0.0}
    
    def __del__(self):
        """–û—á–∏—Å—Ç–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –æ–±—ä–µ–∫—Ç–∞"""
        self.resource_monitor.stop_monitoring() 